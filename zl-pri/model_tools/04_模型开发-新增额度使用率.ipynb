{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/wj/新浪数科/模型开发/\")\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scorecardpy as sc\n",
    "import pickle\n",
    "from model_tools.metrics import roc_auc_score, ks\n",
    "from model_tools.ScoreCard import model_helper\n",
    "from model_tools.Model import model_utils\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.read_csv(\"../input/FT4_0_MODEL_DATA_230418.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12894731.0\n",
       "1    73240190.0\n",
       "2         229.0\n",
       "3     1472304.0\n",
       "4         438.0\n",
       "Name: diff_pass_credit_first_loan_time, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data[\"diff_pass_credit_first_loan_time\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_behavior_data = pd.read_csv(\"../input/ft4_0_loan_behavior_variables_20230509.csv\")\n",
    "loan_behavior_variables = list(loan_behavior_data.columns[8:])\n",
    "model_data.drop(['dpd30_at_mob6'], axis=1, inplace=True)\n",
    "model_data = model_data.merge(loan_behavior_data[['biz_id', 'dpd15_at_mob1', 'dpd30_at_mob6']+loan_behavior_variables], left_on='loan_id', right_on='biz_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data.to_csv(\"../output/FT3_2_MODEL_DATA_230510.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_behavior_variables = ['loan_apply_count',\n",
    " 'loan_apply_count_15d',\n",
    " 'loan_apply_count_30d',\n",
    " 'loan_apply_count_60d',\n",
    " 'loan_apply_count_90d',\n",
    " 'loan_apply_count_180d',\n",
    " 'loan_apply_count_360d',\n",
    " 'loan_term3_apply_count',\n",
    " 'loan_term6_apply_count',\n",
    " 'loan_term12_apply_count',\n",
    " 'loan_hour06_apply_count',\n",
    " 'loan_hour12_apply_count',\n",
    " 'loan_hour18_apply_count',\n",
    " 'loan_hour24_apply_count',\n",
    " 'first_reject_to_now_days',\n",
    " 'recent_reject_to_now_days']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 额度使用率\n",
    "limit_used_data = pd.read_csv(\"../input/limit_used_rate_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_used_data['limit_used_rate'] = limit_used_data['apply_amount']/limit_used_data['orders_curr_total_limit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_behavior_variables_2 = [\n",
    "    'bankcardauthcount', 'communicationauthcount',\n",
    "   'emercontactcount', 'bank_phone_same', 'location_same_province',\n",
    "   'diff_storage_mobile_time', 'diff_storage_credit_time',\n",
    "   'diff_mobile_bank_time', 'diff_bank_carrier_time',\n",
    "   'diff_carrier_credit_time', 'first_credit_hour', 'first_credit_week',\n",
    "   'first_credit_weekend', \n",
    "   'first_credit_succ_hour', 'first_credit_succ_week',\n",
    "   'first_credit_succ_weekend', 'first_loan_hour', 'first_loan_week',\n",
    "   'first_loan_weekend', 'diff_wb_reg_first_loan_time',\n",
    "   'diff_wb_reg_first_credit_time', 'city_level_card_num',\n",
    "   'city_level_mobile_num', 'city_level_bank_num', 'mobile_unbound_times',\n",
    "    'user_name_is_figure_or_alphabet',\n",
    "   'emer_contact_user1_name_is_figure_or_alphabet',\n",
    "   'emer_contact_user2_name_is_figure_or_alphabet',\n",
    "   'user_emer1_emer2_name_no_equal', 'user_emer1_emer2_mobile_no_equal',\n",
    "   'id_card_expire_diff_now_days', 'cardfrontkeysize', 'cardbackkeysize',\n",
    "   'contracts_count', \n",
    "   'limit_used_rate', \n",
    "   'wheneverloan_loan_info_diff_pass_credit_first_loan_time',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>now_host_amount_rate</th>\n",
       "      <th>limit_used_rate</th>\n",
       "      <th>orders_curr_total_limit</th>\n",
       "      <th>apply_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2200.0</td>\n",
       "      <td>2200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2020</td>\n",
       "      <td>0.202020</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.027855</td>\n",
       "      <td>35900.0</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101549</th>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101552</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>5000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101570</th>\n",
       "      <td>0.7692</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>10000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101586</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101587</th>\n",
       "      <td>0.3824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18691 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        now_host_amount_rate  limit_used_rate  orders_curr_total_limit  \\\n",
       "0                     0.0200         0.020000                  50000.0   \n",
       "3                     1.0000         1.000000                   2200.0   \n",
       "13                    0.2020         0.202020                  49500.0   \n",
       "16                    0.0279         0.027855                  35900.0   \n",
       "20                    1.0000         1.000000                   2000.0   \n",
       "...                      ...              ...                      ...   \n",
       "101549                0.0167         0.016667                  30000.0   \n",
       "101552                0.3333         0.333333                  15000.0   \n",
       "101570                0.7692         0.769231                  13000.0   \n",
       "101586                1.0000              NaN                      NaN   \n",
       "101587                0.3824              NaN                      NaN   \n",
       "\n",
       "        apply_amount  \n",
       "0             1000.0  \n",
       "3             2200.0  \n",
       "13           10000.0  \n",
       "16            1000.0  \n",
       "20            2000.0  \n",
       "...              ...  \n",
       "101549         500.0  \n",
       "101552        5000.0  \n",
       "101570       10000.0  \n",
       "101586           NaN  \n",
       "101587           NaN  \n",
       "\n",
       "[18691 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit_used_data.query(\"now_host_amount_rate==now_host_amount_rate\")[['now_host_amount_rate', 'limit_used_rate', 'orders_curr_total_limit', 'apply_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_used_data.rename(columns={'biz_id': 'loan_id'}, inplace=True)\n",
    "model_data = model_data.merge(limit_used_data[['loan_id']+loan_behavior_variables_2], on='loan_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04</th>\n",
       "      <td>11077.0</td>\n",
       "      <td>542.0</td>\n",
       "      <td>0.048930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05</th>\n",
       "      <td>15260.0</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.050852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06</th>\n",
       "      <td>13108.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0.048978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07</th>\n",
       "      <td>12263.0</td>\n",
       "      <td>487.0</td>\n",
       "      <td>0.039713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08</th>\n",
       "      <td>11168.0</td>\n",
       "      <td>532.0</td>\n",
       "      <td>0.047636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09</th>\n",
       "      <td>10662.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>0.047833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10</th>\n",
       "      <td>10803.0</td>\n",
       "      <td>598.0</td>\n",
       "      <td>0.055355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count    bad  bad_rate\n",
       "apply_month                          \n",
       "2022-04      11077.0  542.0  0.048930\n",
       "2022-05      15260.0  776.0  0.050852\n",
       "2022-06      13108.0  642.0  0.048978\n",
       "2022-07      12263.0  487.0  0.039713\n",
       "2022-08      11168.0  532.0  0.047636\n",
       "2022-09      10662.0  510.0  0.047833\n",
       "2022-10      10803.0  598.0  0.055355"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f_mi(x, target):\n",
    "    d = []\n",
    "    d.append(x['cnt'].sum())\n",
    "    d.append(x[target].sum())\n",
    "    d.append(x[target].mean())\n",
    "    return pd.Series(d, index=['count', 'bad', 'bad_rate'])\n",
    "\n",
    "model_data['cnt'] = 1\n",
    "model_data.query(\"dpd30_at_mob3!=-1\").groupby([\"apply_month\"]).apply(f_mi, \"dpd30_at_mob3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04</th>\n",
       "      <td>10179.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>0.119855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05</th>\n",
       "      <td>13905.0</td>\n",
       "      <td>1705.0</td>\n",
       "      <td>0.122618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06</th>\n",
       "      <td>12664.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.126342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07</th>\n",
       "      <td>11375.0</td>\n",
       "      <td>1271.0</td>\n",
       "      <td>0.111736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08</th>\n",
       "      <td>10372.0</td>\n",
       "      <td>1107.0</td>\n",
       "      <td>0.106730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09</th>\n",
       "      <td>9616.0</td>\n",
       "      <td>760.0</td>\n",
       "      <td>0.079035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10</th>\n",
       "      <td>2777.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.087144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count     bad  bad_rate\n",
       "apply_month                           \n",
       "2022-04      10179.0  1220.0  0.119855\n",
       "2022-05      13905.0  1705.0  0.122618\n",
       "2022-06      12664.0  1600.0  0.126342\n",
       "2022-07      11375.0  1271.0  0.111736\n",
       "2022-08      10372.0  1107.0  0.106730\n",
       "2022-09       9616.0   760.0  0.079035\n",
       "2022-10       2777.0   242.0  0.087144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.query(\"dpd30_at_mob6!=[-1, -9999]\").groupby([\"apply_month\"]).apply(f_mi, \"dpd30_at_mob6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>bad</th>\n",
       "      <th>bad_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apply_month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-04</th>\n",
       "      <td>12665.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.009712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-05</th>\n",
       "      <td>17443.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>0.011982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06</th>\n",
       "      <td>15462.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.009766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-07</th>\n",
       "      <td>13896.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.007412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08</th>\n",
       "      <td>12872.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-09</th>\n",
       "      <td>11795.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.009580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10</th>\n",
       "      <td>12056.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.010783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count    bad  bad_rate\n",
       "apply_month                          \n",
       "2022-04      12665.0  123.0  0.009712\n",
       "2022-05      17443.0  209.0  0.011982\n",
       "2022-06      15462.0  151.0  0.009766\n",
       "2022-07      13896.0  103.0  0.007412\n",
       "2022-08      12872.0  108.0  0.008390\n",
       "2022-09      11795.0  113.0  0.009580\n",
       "2022-10      12056.0  130.0  0.010783"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.query(\"dpd15_at_mob1!=[-1, -9999]\").groupby([\"apply_month\"]).apply(f_mi, \"dpd15_at_mob1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_variables = [\"gender\", \"age\", \"idcardpre6\", \"diff_pass_credit_first_loan_time\"]\n",
    "wb_score = ['wb_v2_0_confidence', 'wb_v2_0_prob']\n",
    "br_variables = [x for x in model_data.columns if x.startswith(\"als_\") and not x.endswith(\"_status\")]\n",
    "wb_variables = [x for x in model_data.columns if x.startswith(\"sina\") and not x.endswith(\"_status\")] + ['now_duration_weibo_reg']\n",
    "ronghui_p_variables = [x for x in model_data.columns if x.startswith(\"ronghui_p\") and not x.endswith(\"_status\")]\n",
    "tx_risk_score = ['tx_riskscore']\n",
    "blz_tz_score = ['bileizhen_tuzhi_10_score']\n",
    "youmeng_score = [\"youmeng_bank_score\"]\n",
    "jd_variables = [x for x in model_data.columns if x.startswith(\"jd_\") and not x.endswith(\"_status\")]\n",
    "hudao_variables = [x for x in model_data.columns if x.startswith(\"hd_\") and not x.endswith(\"_status\")]\n",
    "dxm_score = ['dxm_general_fraudc_v3_score']\n",
    "bw_score = ['bw_b_score_v3']\n",
    "ks_variables = [x for x in model_data.columns if x.startswith(\"ppde_\") and not x.endswith(\"_status\")]\n",
    "jd_variables1 = [\n",
    "    'jd_ppre_has_child_score',\n",
    "    'jd_ppre_consm_tob_level',\n",
    "    'jd_ppre_purch_score',\n",
    "    'jd_ppre_lux_pref_score',\n",
    "    'jd_ppre_have_house_score'\n",
    "]\n",
    "jd_variables2 = [\n",
    "    'jd_ppre_intst_rate_sens_level',\n",
    "    'jd_ppre_credit_asst_level',\n",
    "    'jd_ppre_debit_level',\n",
    "    'jd_ppre_device_price_level',\n",
    "]\n",
    "\n",
    "loan_behavior_variables = ['loan_apply_count',\n",
    " 'loan_apply_count_15d',\n",
    " 'loan_apply_count_30d',\n",
    " 'loan_apply_count_60d',\n",
    " 'loan_apply_count_90d',\n",
    " 'loan_apply_count_180d',\n",
    " 'loan_apply_count_360d',\n",
    " 'loan_term3_apply_count',\n",
    " 'loan_term6_apply_count',\n",
    " 'loan_term12_apply_count',\n",
    " 'loan_hour06_apply_count',\n",
    " 'loan_hour12_apply_count',\n",
    " 'loan_hour18_apply_count',\n",
    " 'loan_hour24_apply_count',\n",
    " 'first_reject_to_now_days',\n",
    " 'recent_reject_to_now_days']\n",
    "\n",
    "condicate_variables = nb_variables +\\\n",
    "    wb_score +\\\n",
    "    br_variables +\\\n",
    "    ronghui_p_variables +\\\n",
    "    tx_risk_score +\\\n",
    "    youmeng_score +\\\n",
    "    hudao_variables +\\\n",
    "    dxm_score +\\\n",
    "    bw_score +\\\n",
    "    ks_variables +\\\n",
    "    jd_variables2 +\\\n",
    "    loan_behavior_variables +\\\n",
    "    loan_behavior_variables_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_report = model_helper.data_report(model_data[condicate_variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from woe_bin import woe_bin\n",
    "\n",
    "# temp = model_data.query(\"dpd30_at_mob6 != [-9999, -1]\")[condicate_variables+[\"dpd30_at_mob6\"]]\n",
    "# mono_woe = woe_bin(indata=temp, target=\"dpd30_at_mob6\", min_group_rate=0.05, max_bin=6, bin_method='mono', alg_method='iv')\n",
    "# mapiv_temp = mono_woe.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapiv_temp.sort_values(['iv', 'varname'], ascending=[False, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapiv_temp.to_csv(\"../output/mono_woe_mob6_230509.csv\", index=False)\n",
    "mapiv_temp = pd.read_csv(\"../output/mono_woe_mob6_230509.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_iv_variables = [x for x in mapiv_temp.query(\"iv >= 0.001\")['varname'].drop_duplicates().tolist() if x in condicate_variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"\"\"\"\"\"\n",
    "result += \"def process(model_data):\\n\"\n",
    "result += \"  import numpy as np\\n\"\n",
    "for col in select_iv_variables:\n",
    "    bins_info_temp = mapiv_temp.query(f\"varname=='{col}'\")\n",
    "    have_null = 1-int(bins_info_temp['bin'].tolist()[0])\n",
    "    # woe transformer\n",
    "    for index, left, right, woe in zip(bins_info_temp['bin'].tolist(), \n",
    "                                bins_info_temp['ll'].tolist(),\n",
    "                                bins_info_temp['ul'].tolist(),\n",
    "                                bins_info_temp['woe'].tolist()):\n",
    "        \n",
    "        if have_null:\n",
    "            if str(left) == \"nan\" and str(right) == \"nan\":\n",
    "                result += f\"  model_data['W_{col}'] = \\\\\\n    np.where(model_data['{col}'].isnull(),     {woe},\\n\"\n",
    "            elif str(right) == \"inf\":\n",
    "                result += f\"  {woe}\" + \")\"*int(index) + \"\\n\\n\"\n",
    "            else:\n",
    "                result += f\"    np.where(model_data['{col}'] < {right},        {woe},\\n\"\n",
    "        else:\n",
    "            if int(index)==1:\n",
    "                result += f\"  model_data['W_{col}'] = \\\\\\n    np.where(model_data['{col}'] <{right},     {woe},\\n\"\n",
    "            elif str(right) == \"inf\":\n",
    "                result += f\"  {woe}\" + \")\"*(int(index)-1) + \"\\n\\n\"\n",
    "            else:\n",
    "                result += f\"    np.where(model_data['{col}'] < {right},        {woe},\\n\"\n",
    "            \n",
    "result += \"  return model_data\"\n",
    " \n",
    "print(result, file=open(\"condition_calculate_mob6_230509.py\", \"w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import condition_calculate_mob6_230509\n",
    "from imp import reload\n",
    "reload(condition_calculate_mob6_230509)\n",
    "\n",
    "model_data = condition_calculate_mob6_230509.process(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sample1 = model_data.query(\"apply_month>='2022-04' and apply_month<='2022-07' and dpd30_at_mob6!=[-1, -9999]\").reset_index(drop=True)\n",
    "oot_sample1 = model_data.query(\"apply_month>='2022-08' and apply_month<='2022-10' and dpd30_at_mob6!=[-1, -9999]\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train SAMPLE SIZE: 33686, BAD: 4057, BAD RATIO: 0.1204\n",
      "Validation SAMPLE SIZE: 14437, BAD: 1739, BAD RATIO: 0.1205\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "target = \"dpd30_at_mob6\"\n",
    "train, validation = train_test_split(dev_sample1, test_size=0.3, random_state=42)\n",
    "print(\"Train SAMPLE SIZE: %d, BAD: %d, BAD RATIO: %.4f\" %\n",
    "      (train.shape[0], train[target].sum(), train[target].mean()))\n",
    "print(\"Validation SAMPLE SIZE: %d, BAD: %d, BAD RATIO: %.4f\" %\n",
    "      (validation.shape[0], validation[target].sum(), validation[target].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "condicate_variables1 = nb_variables +\\\n",
    "    wb_score +\\\n",
    "    br_variables +\\\n",
    "    tx_risk_score +\\\n",
    "    youmeng_score +\\\n",
    "    dxm_score +\\\n",
    "    bw_score +\\\n",
    "    ks_variables +\\\n",
    "    jd_variables2 +\\\n",
    "    loan_behavior_variables +\\\n",
    "    loan_behavior_variables_2\n",
    "\n",
    "condicate_variables2 = nb_variables +\\\n",
    "    wb_score +\\\n",
    "    br_variables +\\\n",
    "    ronghui_p_variables +\\\n",
    "    tx_risk_score +\\\n",
    "    youmeng_score +\\\n",
    "    dxm_score +\\\n",
    "    bw_score +\\\n",
    "    ks_variables +\\\n",
    "    jd_variables2 +\\\n",
    "    loan_behavior_variables +\\\n",
    "    ['limit_used_rate']\n",
    "\n",
    "input_cols = [x for x in mapiv_temp.query(\"varname==@condicate_variables2 and iv >= 0.01\")['varname'].drop_duplicates().tolist()]\n",
    "input_woe_variables = ['W_'+x for x in input_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.696956\tvalidation_1-auc:0.689117\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 20 rounds.\n",
      "[20]\tvalidation_0-auc:0.745373\tvalidation_1-auc:0.735571\n",
      "[40]\tvalidation_0-auc:0.761193\tvalidation_1-auc:0.747949\n",
      "[60]\tvalidation_0-auc:0.771151\tvalidation_1-auc:0.754463\n",
      "[80]\tvalidation_0-auc:0.779315\tvalidation_1-auc:0.760282\n",
      "[100]\tvalidation_0-auc:0.785971\tvalidation_1-auc:0.763725\n",
      "[119]\tvalidation_0-auc:0.790446\tvalidation_1-auc:0.765046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(colsample_bytree=0.9, gamma=0.1, learning_rate=0.08, max_depth=4,\n",
       "              min_child_weight=150, n_estimators=120, n_jobs=-1, nthread=-1,\n",
       "              reg_alpha=0.1, reg_lambda=0.1, seed=42, silent=True,\n",
       "              subsample=0.9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model = XGBClassifier(\n",
    "    base_score=0.5,\n",
    "    colsample_bylevel=1,\n",
    "    colsample_bytree=0.9,\n",
    "    gamma=0.1,\n",
    "    learning_rate=0.08,\n",
    "    max_depth=4,\n",
    "    min_child_weight=150,\n",
    "    missing=None,\n",
    "    n_estimators=120,\n",
    "    nthread=-1,\n",
    "    n_jobs=-1,\n",
    "    objective='binary:logistic',\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.1,\n",
    "    scale_pos_weight=1,\n",
    "    seed=42,\n",
    "    silent=True,\n",
    "    subsample=0.9\n",
    ")\n",
    "\n",
    "\n",
    "xgb_model.fit(train[input_woe_variables], train[target], eval_set=[(train[input_woe_variables], train[target]), (validation[input_woe_variables], validation[target])],\n",
    "         eval_metric='auc', early_stopping_rounds=20, verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = xgb_model.get_booster().predict(xgb.DMatrix(dev_sample1[input_woe_variables]), pred_contribs=True)     \n",
    "shap_df = pd.DataFrame(np.abs(shap_values[:,:-1]), columns=input_woe_variables)\n",
    "\n",
    "shap_imp = shap_df.mean().sort_values(ascending=False).reset_index()\n",
    "shap_imp.columns = ['Feature', 'Shap_Importance']\n",
    "shap_imp = shap_imp[shap_imp['Shap_Importance']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Shap_Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W_wb_v2_0_prob</td>\n",
       "      <td>0.258167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W_dxm_general_fraudc_v3_score</td>\n",
       "      <td>0.240363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W_limit_used_rate</td>\n",
       "      <td>0.225612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W_bw_b_score_v3</td>\n",
       "      <td>0.216126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W_tx_riskscore</td>\n",
       "      <td>0.190768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W_age</td>\n",
       "      <td>0.187881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W_ppde_7d_itfin_cashloan_cnt</td>\n",
       "      <td>0.102702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>W_ppde_30d_itfin_cashloan_cnt</td>\n",
       "      <td>0.069378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W_diff_pass_credit_first_loan_time</td>\n",
       "      <td>0.067631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>W_idcardpre6</td>\n",
       "      <td>0.058216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Feature  Shap_Importance\n",
       "0                      W_wb_v2_0_prob         0.258167\n",
       "1       W_dxm_general_fraudc_v3_score         0.240363\n",
       "2                   W_limit_used_rate         0.225612\n",
       "3                     W_bw_b_score_v3         0.216126\n",
       "4                      W_tx_riskscore         0.190768\n",
       "5                               W_age         0.187881\n",
       "6        W_ppde_7d_itfin_cashloan_cnt         0.102702\n",
       "7       W_ppde_30d_itfin_cashloan_cnt         0.069378\n",
       "8  W_diff_pass_credit_first_loan_time         0.067631\n",
       "9                        W_idcardpre6         0.058216"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_imp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9418915"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_imp.head(80)['Shap_Importance'].sum()/shap_imp['Shap_Importance'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_cols = [x for x in shap_imp.head(80)['Feature'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sel_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from six.moves import xrange\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "\n",
    "class FocalLossObjective(object):\n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        # approxes, targets, weights are indexed containers of floats\n",
    "        # (containers with only __len__ and __getitem__ defined).\n",
    "        # weights parameter can be None.\n",
    "        # Returns list of pairs (der1, der2)\n",
    "        gamma = 2.\n",
    "        # alpha = 1.\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "        \n",
    "        exponents = []\n",
    "        for index in xrange(len(approxes)):\n",
    "            exponents.append(math.exp(approxes[index]))\n",
    "\n",
    "        result = []\n",
    "        for index in xrange(len(targets)):\n",
    "            p = exponents[index] / (1 + exponents[index])\n",
    "\n",
    "            if targets[index] > 0.0:\n",
    "                der1 = -((1-p)**(gamma-1))*(gamma * math.log(p) * p + p - 1)/p\n",
    "                der2 = gamma*((1-p)**gamma)*((gamma*p-1)*math.log(p)+2*(p-1))\n",
    "            else:\n",
    "                der1 = (p**(gamma-1)) * (gamma * math.log(1 - p) - p)/(1 - p)\n",
    "                der2 = p**(gamma-2)*((p*(2*gamma*(p-1)-p))/(p-1)**2 + (gamma-1)*gamma*math.log(1 - p))\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 400, \n",
    "    'objective': 'CrossEntropy', \n",
    "    'bootstrap_type': 'Bernoulli', \n",
    "    'eval_metric':'AUC',\n",
    "    'od_wait': 10, \n",
    "    'learning_rate': 0.05, \n",
    "    'reg_lambda': 2, \n",
    "    'random_strength': 4, \n",
    "    'random_state': 2023,\n",
    "    'depth': 4, \n",
    "    'min_data_in_leaf': 415, \n",
    "    'leaf_estimation_iterations': 4, \n",
    "    'subsample': 0.9449700103203925,\n",
    "    'verbose' : 1,\n",
    "    'loss_function' : FocalLossObjective(),\n",
    "}\n",
    "\n",
    "cat_params =  {'bootstrap_type': 'Bernoulli', 'objective': 'CrossEntropy', 'eval_metric':'AUC', 'iterations': 400, 'od_wait': 6, 'random_strength': 4, 'max_bin': 4, 'reg_lambda': 7, 'subsample': 0.9218331876323019, \n",
    "               'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 3, 'random_state': 2023, 'min_data_in_leaf': 309, 'loss_function' : FocalLossObjective()\n",
    "              }\n",
    "\n",
    "cat_params =  {'bootstrap_type': 'Bernoulli', 'objective': 'CrossEntropy', 'eval_metric':'AUC', 'iterations': 400, 'loss_function' : FocalLossObjective(), 'od_wait': 7, 'random_strength': 4, 'max_bin': 5, 'reg_lambda': 8, 'subsample': 0.928854767323812, 'learning_rate': 0.05, \n",
    " 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 485}\n",
    "\n",
    "cat_params =  {'bootstrap_type': 'Bernoulli', 'objective': 'CrossEntropy', 'eval_metric':'AUC', 'iterations': 400, 'od_wait': 10, 'random_strength': 5, \n",
    "               'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8877390866014263, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 467,\n",
    "              'loss_function' : FocalLossObjective()\n",
    "              }\n",
    "# cat_params = {\n",
    "#     'iterations': 400, \n",
    "#     'objective': 'CrossEntropy', \n",
    "#     'bootstrap_type': 'Bernoulli', \n",
    "#     'eval_metric':'AUC',\n",
    "#     'od_wait': 4, \n",
    "#     'learning_rate': 0.05, \n",
    "#     'reg_lambda': 1, \n",
    "#     'random_strength': 4, \n",
    "#     'random_state': 42,\n",
    "#     'depth': 4, \n",
    "#     'min_data_in_leaf': 234, \n",
    "#     'leaf_estimation_iterations': 7, \n",
    "#     'subsample': 0.8811664288639238,\n",
    "#     'verbose' : 1,\n",
    "#     'loss_function' : FocalLossObjective(),\n",
    "# }\n",
    "\n",
    "# {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.8811664288639238, \n",
    "#  'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 234}\n",
    "\n",
    "#  {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9004534526114775, \n",
    "#   'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 335}\n",
    "    \n",
    "# {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 4, 'reg_lambda': 2, 'subsample': 0.9449700103203925, \n",
    "#  'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 415}\n",
    "\n",
    "# cat_params = {'bootstrap_type': 'Bernoulli', 'eval_metric':'AUC', 'od_wait': 8, 'random_strength': 4, 'max_bin': 5, 'reg_lambda': 2, 'subsample': 0.9158264114777777, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 487}\n",
    "# cat_params = {'bootstrap_type': 'Bernoulli','eval_metric':'AUC','od_wait': 10, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 2, 'subsample': 0.9816944236770894, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 434}\n",
    "cat_model2 = CatBoostClassifier(**cat_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5575458\ttest1: 0.5552233\tbest: 0.5552233 (0)\ttotal: 9.49ms\tremaining: 3.79s\n",
      "20:\ttest: 0.6943523\ttest1: 0.6614063\tbest: 0.6614063 (20)\ttotal: 183ms\tremaining: 3.3s\n",
      "40:\ttest: 0.7352071\ttest1: 0.7017134\tbest: 0.7021537 (38)\ttotal: 392ms\tremaining: 3.43s\n",
      "60:\ttest: 0.7499658\ttest1: 0.7173739\tbest: 0.7173739 (60)\ttotal: 628ms\tremaining: 3.49s\n",
      "80:\ttest: 0.7539735\ttest1: 0.7196156\tbest: 0.7197563 (75)\ttotal: 790ms\tremaining: 3.11s\n",
      "100:\ttest: 0.7601288\ttest1: 0.7254568\tbest: 0.7254568 (100)\ttotal: 999ms\tremaining: 2.96s\n",
      "120:\ttest: 0.7634106\ttest1: 0.7282116\tbest: 0.7282116 (120)\ttotal: 1.18s\tremaining: 2.72s\n",
      "140:\ttest: 0.7675793\ttest1: 0.7314276\tbest: 0.7314276 (140)\ttotal: 1.35s\tremaining: 2.48s\n",
      "160:\ttest: 0.7703767\ttest1: 0.7337648\tbest: 0.7339035 (159)\ttotal: 1.54s\tremaining: 2.29s\n",
      "180:\ttest: 0.7724666\ttest1: 0.7348176\tbest: 0.7348176 (180)\ttotal: 1.77s\tremaining: 2.14s\n",
      "200:\ttest: 0.7748273\ttest1: 0.7363196\tbest: 0.7363196 (200)\ttotal: 1.97s\tremaining: 1.95s\n",
      "220:\ttest: 0.7773517\ttest1: 0.7384577\tbest: 0.7384577 (220)\ttotal: 2.17s\tremaining: 1.76s\n",
      "240:\ttest: 0.7798303\ttest1: 0.7400106\tbest: 0.7400255 (239)\ttotal: 2.36s\tremaining: 1.55s\n",
      "260:\ttest: 0.7825129\ttest1: 0.7417595\tbest: 0.7417595 (260)\ttotal: 2.52s\tremaining: 1.34s\n",
      "280:\ttest: 0.7847922\ttest1: 0.7422406\tbest: 0.7422406 (280)\ttotal: 2.71s\tremaining: 1.15s\n",
      "300:\ttest: 0.7877049\ttest1: 0.7435961\tbest: 0.7436032 (299)\ttotal: 2.9s\tremaining: 955ms\n",
      "320:\ttest: 0.7900014\ttest1: 0.7438869\tbest: 0.7438869 (320)\ttotal: 3.07s\tremaining: 756ms\n",
      "340:\ttest: 0.7925573\ttest1: 0.7453426\tbest: 0.7453426 (340)\ttotal: 3.24s\tremaining: 561ms\n",
      "360:\ttest: 0.7949517\ttest1: 0.7460893\tbest: 0.7460893 (360)\ttotal: 3.41s\tremaining: 369ms\n",
      "380:\ttest: 0.7968263\ttest1: 0.7464275\tbest: 0.7464275 (380)\ttotal: 3.6s\tremaining: 179ms\n",
      "399:\ttest: 0.7988485\ttest1: 0.7471098\tbest: 0.7471098 (399)\ttotal: 3.75s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.7471097825\n",
      "bestIteration = 399\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7fc62691f850>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model2.fit(train[sel_cols], train[target], eval_set=[(train[sel_cols], train[target]), (oot_sample1[sel_cols], oot_sample1[target])],\n",
    "         early_stopping_rounds=20, verbose=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 400,\n",
       " 'learning_rate': 0.05,\n",
       " 'depth': 4,\n",
       " 'loss_function': <__main__.FocalLossObjective at 0x7fc629132a10>,\n",
       " 'od_wait': 10,\n",
       " 'leaf_estimation_iterations': 3,\n",
       " 'random_strength': 5,\n",
       " 'eval_metric': 'AUC',\n",
       " 'bootstrap_type': 'Bernoulli',\n",
       " 'subsample': 0.8877390866014263,\n",
       " 'random_state': 2023,\n",
       " 'reg_lambda': 2,\n",
       " 'objective': 'CrossEntropy',\n",
       " 'max_bin': 7,\n",
       " 'min_data_in_leaf': 467}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_model2.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['ft3_2_proba_v2'] = cat_model2.predict_proba(model_data[sel_cols])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def score_card(prob):\n",
    "    base_score = 600\n",
    "    base_odds = 1/50\n",
    "    PDO = 50\n",
    "    B = PDO*1.0/math.log(2)\n",
    "    A = base_score + B*math.log(base_odds)\n",
    "    return round(A - B*math.log(prob/ (1-prob+1e-20)),0)\n",
    "\n",
    "model_data['ft3_2_score_v2'] = model_data['ft3_2_proba_v2'].apply(score_card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_map(x):\n",
    "    if x<'2022-08':\n",
    "        return '0.Train'\n",
    "    else:\n",
    "        return '1.OOT'\n",
    "\n",
    "model_data['source'] = model_data['apply_month'].apply(lambda x: source_map(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Count</th>\n",
       "      <th>#Bad</th>\n",
       "      <th>%Bad</th>\n",
       "      <th>%Bad(灰当白)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>KS</th>\n",
       "      <th>AUC(灰当白)</th>\n",
       "      <th>KS(灰当白)</th>\n",
       "      <th>Capture@top10%</th>\n",
       "      <th>Lift@top10%</th>\n",
       "      <th>Lift_Repair@top10%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.Train</th>\n",
       "      <td>63365.0</td>\n",
       "      <td>5796.0</td>\n",
       "      <td>0.120441</td>\n",
       "      <td>0.091470</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.429</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.336</td>\n",
       "      <td>3.356</td>\n",
       "      <td>4.169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.OOT</th>\n",
       "      <td>29918.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>0.070493</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.974</td>\n",
       "      <td>3.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          #Count    #Bad      %Bad  %Bad(灰当白)    AUC     KS  AUC(灰当白)  \\\n",
       "source                                                                  \n",
       "0.Train  63365.0  5796.0  0.120441   0.091470  0.791  0.429     0.774   \n",
       "1.OOT    29918.0  2109.0  0.092642   0.070493  0.747  0.366     0.731   \n",
       "\n",
       "         KS(灰当白)  Capture@top10%  Lift@top10%  Lift_Repair@top10%  \n",
       "source                                                             \n",
       "0.Train    0.403           0.336        3.356               4.169  \n",
       "1.OOT      0.342           0.297        2.974               3.392  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def capture_topk(y_ture, y_pred, top=20):\n",
    "    sort_index = np.argsort(-y_pred)\n",
    "    y_ture_sort = y_ture[sort_index]\n",
    "    topk = int(len(y_pred)*top/100)\n",
    "    return np.sum(y_ture_sort[:topk])/np.sum(y_ture_sort)\n",
    "\n",
    "\n",
    "def lift_topk(y_ture, y_pred, top=20):\n",
    "    sort_index = np.argsort(-y_pred)\n",
    "    y_ture_sort = y_ture[sort_index]\n",
    "    topk = int(len(y_pred)*top/100)\n",
    "    return (np.sum(y_ture_sort[:topk])/topk)/(np.sum(y_ture_sort)/len(y_ture))\n",
    "\n",
    "# def lift_repair(data, cut_off, target, score, adjust_bad_rate, adjust_good_rate):\n",
    "#     rj_sample_1 = data.query(f\"{score} < @cut_off and {target}==1\").shape[0]\n",
    "#     rj_sample_0 = data.query(f\"{score} < @cut_off and {target}==0\").shape[0]\n",
    "#     ps_sample_1 = data.query(f\"{score} >= @cut_off and {target}==1\").shape[0]\n",
    "#     ps_sample_0 = data.query(f\"{score} >= @cut_off and {target}==0\").shape[0]\n",
    "#     l = (rj_sample_1/adjust_bad_rate)/(rj_sample_1/adjust_bad_rate+rj_sample_0/adjust_good_rate)*\\\n",
    "#     (1+(rj_sample_0/adjust_good_rate +ps_sample_0/adjust_good_rate)/(rj_sample_1/adjust_bad_rate+ps_sample_1/adjust_bad_rate))\n",
    "#     return l\n",
    "\n",
    "def lift_repair_topk(y_ture, y_pred, adjust_bad_rate, adjust_good_rate, top=20):\n",
    "    sort_index = np.argsort(-y_pred)\n",
    "    y_ture_sort = y_ture[sort_index]\n",
    "    topk = int(len(y_pred)*top/100)\n",
    "    rj_sample_1 = np.sum(y_ture_sort[:topk])\n",
    "    rj_sample_0 = topk - rj_sample_1\n",
    "    ps_sample_1 = np.sum(y_ture_sort[topk:])\n",
    "    ps_sample_0 = len(y_ture_sort[topk:]) - ps_sample_1\n",
    "    return (rj_sample_1/adjust_bad_rate)/(rj_sample_1/adjust_bad_rate+rj_sample_0/adjust_good_rate)*\\\n",
    "    (1+(rj_sample_0/adjust_good_rate +ps_sample_0/adjust_good_rate)/(rj_sample_1/adjust_bad_rate+ps_sample_1/adjust_bad_rate))\n",
    "\n",
    "def f_evalutor(x, proba_name, target):\n",
    "    d = []\n",
    "    d.append(x['cnt'].sum())\n",
    "    d.append(x.query(f\"{target}==[0, 1]\")[target].sum())\n",
    "    d.append(x.query(f\"{target}==[0, 1]\")[target].mean())\n",
    "    d.append(x[target].replace(-1, 0).mean())\n",
    "    d.append(round(roc_auc_score(x.query(f\"{target}!=-1\")[target], x.query(f\"{target}!=-1\")[proba_name]), 3))\n",
    "    d.append(round(ks(x.query(f\"{target}!=-1\")[target], x.query(f\"{target}!=-1\")[proba_name]),3))\n",
    "    d.append(round(roc_auc_score(x[target].replace(-1, 0), x[proba_name]),3))\n",
    "    d.append(round(ks(x[target].replace(-1, 0), x[proba_name]),3))\n",
    "    # capture@top10%\n",
    "    d.append(round(capture_topk(x.query(f\"{target}!=-1\")[target].values, x.query(f\"{target}!=-1\")[proba_name].values, 10), 3))\n",
    "    # lift@top10%\n",
    "    d.append(round(lift_topk(x.query(f\"{target}!=-1\")[target].values, x.query(f\"{target}!=-1\")[proba_name].values, 10), 3))\n",
    "    # lift_repair@top10%\n",
    "    d.append(round(lift_repair_topk(x.query(f\"{target}!=-1\")[target].values, x.query(f\"{target}!=-1\")[proba_name].values, 0.438, 0.16, 10), 3))\n",
    "    return pd.Series(d, index=['#Count', '#Bad', '%Bad', '%Bad(灰当白)', 'AUC', 'KS', 'AUC(灰当白)', 'KS(灰当白)', 'Capture@top10%', 'Lift@top10%', 'Lift_Repair@top10%'])\n",
    "\n",
    "\n",
    "model_data['cnt'] = 1\n",
    "model_data.query(\"dpd30_at_mob6!=-9999\").groupby([\"source\"]).apply(lambda x: f_evalutor(x, \"ft3_2_proba_v2\", \"dpd30_at_mob6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data['segment'] = model_data['loan_apply_count'].apply(lambda x: 1 if x==0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#Count</th>\n",
       "      <th>#Bad</th>\n",
       "      <th>%Bad</th>\n",
       "      <th>%Bad(灰当白)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>KS</th>\n",
       "      <th>AUC(灰当白)</th>\n",
       "      <th>KS(灰当白)</th>\n",
       "      <th>Capture@top10%</th>\n",
       "      <th>Lift@top10%</th>\n",
       "      <th>Lift_Repair@top10%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>segment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.Train</th>\n",
       "      <th>0</th>\n",
       "      <td>11497.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>0.150167</td>\n",
       "      <td>0.109768</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.447</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.347</td>\n",
       "      <td>3.472</td>\n",
       "      <td>4.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51868.0</td>\n",
       "      <td>4534.0</td>\n",
       "      <td>0.114152</td>\n",
       "      <td>0.087414</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.333</td>\n",
       "      <td>3.331</td>\n",
       "      <td>4.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.OOT</th>\n",
       "      <th>0</th>\n",
       "      <td>3880.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>0.123996</td>\n",
       "      <td>0.091495</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.279</td>\n",
       "      <td>2.792</td>\n",
       "      <td>3.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26038.0</td>\n",
       "      <td>1754.0</td>\n",
       "      <td>0.088132</td>\n",
       "      <td>0.067363</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.337</td>\n",
       "      <td>0.293</td>\n",
       "      <td>2.931</td>\n",
       "      <td>3.309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #Count    #Bad      %Bad  %Bad(灰当白)    AUC     KS  AUC(灰当白)  \\\n",
       "source  segment                                                                 \n",
       "0.Train 0        11497.0  1262.0  0.150167   0.109768  0.802  0.447     0.774   \n",
       "        1        51868.0  4534.0  0.114152   0.087414  0.787  0.425     0.774   \n",
       "1.OOT   0         3880.0   355.0  0.123996   0.091495  0.749  0.377     0.728   \n",
       "        1        26038.0  1754.0  0.088132   0.067363  0.744  0.360     0.729   \n",
       "\n",
       "                 KS(灰当白)  Capture@top10%  Lift@top10%  Lift_Repair@top10%  \n",
       "source  segment                                                            \n",
       "0.Train 0          0.404           0.347        3.472               4.695  \n",
       "        1          0.404           0.333        3.331               4.073  \n",
       "1.OOT   0          0.351           0.279        2.792               3.296  \n",
       "        1          0.337           0.293        2.931               3.309  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.query(\"dpd30_at_mob6!=-9999\").groupby([\"source\", \"segment\"]).apply(lambda x: f_evalutor(x, \"ft3_2_proba_v2\", \"dpd30_at_mob6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#Count</th>\n",
       "      <th>#Bad</th>\n",
       "      <th>%Bad</th>\n",
       "      <th>%Bad(灰当白)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>KS</th>\n",
       "      <th>AUC(灰当白)</th>\n",
       "      <th>KS(灰当白)</th>\n",
       "      <th>Capture@top10%</th>\n",
       "      <th>Lift@top10%</th>\n",
       "      <th>Lift_Repair@top10%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>segment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.Train</th>\n",
       "      <th>0</th>\n",
       "      <td>11497.0</td>\n",
       "      <td>631.0</td>\n",
       "      <td>0.069608</td>\n",
       "      <td>0.054884</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.479</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.439</td>\n",
       "      <td>4.392</td>\n",
       "      <td>5.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51868.0</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.410</td>\n",
       "      <td>4.097</td>\n",
       "      <td>4.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.OOT</th>\n",
       "      <th>0</th>\n",
       "      <td>4858.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>0.075820</td>\n",
       "      <td>0.060930</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.364</td>\n",
       "      <td>0.297</td>\n",
       "      <td>2.976</td>\n",
       "      <td>3.306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34259.0</td>\n",
       "      <td>1344.0</td>\n",
       "      <td>0.046782</td>\n",
       "      <td>0.039231</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.333</td>\n",
       "      <td>3.334</td>\n",
       "      <td>3.591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #Count    #Bad      %Bad  %Bad(灰当白)    AUC     KS  AUC(灰当白)  \\\n",
       "source  segment                                                                 \n",
       "0.Train 0        11497.0   631.0  0.069608   0.054884  0.817  0.479     0.794   \n",
       "        1        51868.0  1816.0  0.042586   0.035012  0.799  0.448     0.785   \n",
       "1.OOT   0         4858.0   296.0  0.075820   0.060930  0.753  0.390     0.736   \n",
       "        1        34259.0  1344.0  0.046782   0.039231  0.766  0.390     0.754   \n",
       "\n",
       "                 KS(灰当白)  Capture@top10%  Lift@top10%  Lift_Repair@top10%  \n",
       "source  segment                                                            \n",
       "0.Train 0          0.441           0.439        4.392               5.209  \n",
       "        1          0.426           0.410        4.097               4.483  \n",
       "1.OOT   0          0.364           0.297        2.976               3.306  \n",
       "        1          0.373           0.333        3.334               3.591  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.query(\"dpd30_at_mob3!=-9999\").groupby([\"source\", \"segment\"]).apply(lambda x: f_evalutor(x, \"ft3_2_proba_v2\", \"dpd30_at_mob3\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>#Count</th>\n",
       "      <th>#Bad</th>\n",
       "      <th>%Bad</th>\n",
       "      <th>%Bad(灰当白)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>KS</th>\n",
       "      <th>AUC(灰当白)</th>\n",
       "      <th>KS(灰当白)</th>\n",
       "      <th>Capture@top10%</th>\n",
       "      <th>Lift@top10%</th>\n",
       "      <th>Lift_Repair@top10%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>segment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.Train</th>\n",
       "      <th>0</th>\n",
       "      <td>11497.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.018370</td>\n",
       "      <td>0.016961</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.821</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.554</td>\n",
       "      <td>5.541</td>\n",
       "      <td>5.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51868.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0.008004</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.422</td>\n",
       "      <td>4.220</td>\n",
       "      <td>4.291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.OOT</th>\n",
       "      <th>0</th>\n",
       "      <td>4858.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.372</td>\n",
       "      <td>3.722</td>\n",
       "      <td>3.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34259.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>0.008458</td>\n",
       "      <td>0.007969</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.432</td>\n",
       "      <td>4.323</td>\n",
       "      <td>4.402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  #Count   #Bad      %Bad  %Bad(灰当白)    AUC     KS  AUC(灰当白)  \\\n",
       "source  segment                                                                \n",
       "0.Train 0        11497.0  195.0  0.018370   0.016961  0.830  0.514     0.821   \n",
       "        1        51868.0  391.0  0.008004   0.007538  0.794  0.446     0.788   \n",
       "1.OOT   0         4858.0   78.0  0.017548   0.016056  0.779  0.433     0.771   \n",
       "        1        34259.0  273.0  0.008458   0.007969  0.784  0.441     0.779   \n",
       "\n",
       "                 KS(灰当白)  Capture@top10%  Lift@top10%  Lift_Repair@top10%  \n",
       "source  segment                                                            \n",
       "0.Train 0          0.500           0.554        5.541               5.855  \n",
       "        1          0.437           0.422        4.220               4.291  \n",
       "1.OOT   0          0.421           0.372        3.722               3.840  \n",
       "        1          0.433           0.432        4.323               4.402  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.query(\"dpd15_at_mob1!=-9999\").groupby([\"source\", \"segment\"]).apply(lambda x: f_evalutor(x, \"ft3_2_proba_v2\", \"dpd15_at_mob1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bad</th>\n",
       "      <th>total_good</th>\n",
       "      <th>total_bad_rate</th>\n",
       "      <th>cnt_group</th>\n",
       "      <th>cnt_bad</th>\n",
       "      <th>cnt_good</th>\n",
       "      <th>group_bad_rate</th>\n",
       "      <th>cum_bad</th>\n",
       "      <th>cum_good</th>\n",
       "      <th>cum_bad_pct</th>\n",
       "      <th>cum_good_pct</th>\n",
       "      <th>KS</th>\n",
       "      <th>ft3_2_proba_v2_min</th>\n",
       "      <th>ft3_2_proba_v2_max</th>\n",
       "      <th>ft3_2_proba_v2_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2277</td>\n",
       "      <td>627</td>\n",
       "      <td>1650</td>\n",
       "      <td>0.275362</td>\n",
       "      <td>627</td>\n",
       "      <td>1650</td>\n",
       "      <td>0.297297</td>\n",
       "      <td>0.079880</td>\n",
       "      <td>0.217417</td>\n",
       "      <td>0.243189</td>\n",
       "      <td>0.857291</td>\n",
       "      <td>0.330424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2276</td>\n",
       "      <td>376</td>\n",
       "      <td>1900</td>\n",
       "      <td>0.165202</td>\n",
       "      <td>1003</td>\n",
       "      <td>3550</td>\n",
       "      <td>0.475581</td>\n",
       "      <td>0.171863</td>\n",
       "      <td>0.303718</td>\n",
       "      <td>0.176695</td>\n",
       "      <td>0.243162</td>\n",
       "      <td>0.205553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2277</td>\n",
       "      <td>316</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.138779</td>\n",
       "      <td>1319</td>\n",
       "      <td>5511</td>\n",
       "      <td>0.625415</td>\n",
       "      <td>0.266799</td>\n",
       "      <td>0.358616</td>\n",
       "      <td>0.136296</td>\n",
       "      <td>0.176670</td>\n",
       "      <td>0.154943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2276</td>\n",
       "      <td>218</td>\n",
       "      <td>2058</td>\n",
       "      <td>0.095782</td>\n",
       "      <td>1537</td>\n",
       "      <td>7569</td>\n",
       "      <td>0.728781</td>\n",
       "      <td>0.366431</td>\n",
       "      <td>0.362350</td>\n",
       "      <td>0.106878</td>\n",
       "      <td>0.136275</td>\n",
       "      <td>0.120698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2276</td>\n",
       "      <td>179</td>\n",
       "      <td>2097</td>\n",
       "      <td>0.078647</td>\n",
       "      <td>1716</td>\n",
       "      <td>9666</td>\n",
       "      <td>0.813656</td>\n",
       "      <td>0.467951</td>\n",
       "      <td>0.345705</td>\n",
       "      <td>0.083013</td>\n",
       "      <td>0.106877</td>\n",
       "      <td>0.094612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2277</td>\n",
       "      <td>152</td>\n",
       "      <td>2125</td>\n",
       "      <td>0.066755</td>\n",
       "      <td>1868</td>\n",
       "      <td>11791</td>\n",
       "      <td>0.885728</td>\n",
       "      <td>0.570827</td>\n",
       "      <td>0.314901</td>\n",
       "      <td>0.063972</td>\n",
       "      <td>0.082998</td>\n",
       "      <td>0.073353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2276</td>\n",
       "      <td>106</td>\n",
       "      <td>2170</td>\n",
       "      <td>0.046573</td>\n",
       "      <td>1974</td>\n",
       "      <td>13961</td>\n",
       "      <td>0.935989</td>\n",
       "      <td>0.675881</td>\n",
       "      <td>0.260108</td>\n",
       "      <td>0.047371</td>\n",
       "      <td>0.063954</td>\n",
       "      <td>0.055488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2277</td>\n",
       "      <td>66</td>\n",
       "      <td>2211</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>2040</td>\n",
       "      <td>16172</td>\n",
       "      <td>0.967283</td>\n",
       "      <td>0.782920</td>\n",
       "      <td>0.184363</td>\n",
       "      <td>0.033003</td>\n",
       "      <td>0.047354</td>\n",
       "      <td>0.040256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2276</td>\n",
       "      <td>52</td>\n",
       "      <td>2224</td>\n",
       "      <td>0.022847</td>\n",
       "      <td>2092</td>\n",
       "      <td>18396</td>\n",
       "      <td>0.991939</td>\n",
       "      <td>0.890589</td>\n",
       "      <td>0.101351</td>\n",
       "      <td>0.019656</td>\n",
       "      <td>0.033002</td>\n",
       "      <td>0.026150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>2277</td>\n",
       "      <td>17</td>\n",
       "      <td>2260</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>2109</td>\n",
       "      <td>20656</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.019648</td>\n",
       "      <td>0.011907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bad  total_good  total_bad_rate  cnt_group  cnt_bad  cnt_good  \\\n",
       "0       2109       20656        0.092642       2277      627      1650   \n",
       "1       2109       20656        0.092642       2276      376      1900   \n",
       "2       2109       20656        0.092642       2277      316      1961   \n",
       "3       2109       20656        0.092642       2276      218      2058   \n",
       "4       2109       20656        0.092642       2276      179      2097   \n",
       "5       2109       20656        0.092642       2277      152      2125   \n",
       "6       2109       20656        0.092642       2276      106      2170   \n",
       "7       2109       20656        0.092642       2277       66      2211   \n",
       "8       2109       20656        0.092642       2276       52      2224   \n",
       "9       2109       20656        0.092642       2277       17      2260   \n",
       "\n",
       "   group_bad_rate  cum_bad  cum_good  cum_bad_pct  cum_good_pct        KS  \\\n",
       "0        0.275362      627      1650     0.297297      0.079880  0.217417   \n",
       "1        0.165202     1003      3550     0.475581      0.171863  0.303718   \n",
       "2        0.138779     1319      5511     0.625415      0.266799  0.358616   \n",
       "3        0.095782     1537      7569     0.728781      0.366431  0.362350   \n",
       "4        0.078647     1716      9666     0.813656      0.467951  0.345705   \n",
       "5        0.066755     1868     11791     0.885728      0.570827  0.314901   \n",
       "6        0.046573     1974     13961     0.935989      0.675881  0.260108   \n",
       "7        0.028986     2040     16172     0.967283      0.782920  0.184363   \n",
       "8        0.022847     2092     18396     0.991939      0.890589  0.101351   \n",
       "9        0.007466     2109     20656     1.000000      1.000000  0.000000   \n",
       "\n",
       "   ft3_2_proba_v2_min  ft3_2_proba_v2_max  ft3_2_proba_v2_avg  \n",
       "0            0.243189            0.857291            0.330424  \n",
       "1            0.176695            0.243162            0.205553  \n",
       "2            0.136296            0.176670            0.154943  \n",
       "3            0.106878            0.136275            0.120698  \n",
       "4            0.083013            0.106877            0.094612  \n",
       "5            0.063972            0.082998            0.073353  \n",
       "6            0.047371            0.063954            0.055488  \n",
       "7            0.033003            0.047354            0.040256  \n",
       "8            0.019656            0.033002            0.026150  \n",
       "9            0.000720            0.019648            0.011907  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_helper.model_group_monitor(model_data.query(\"dpd30_at_mob6!=[-9999, -1] and source=='1.OOT'\"), \"dpd30_at_mob6\", \"ft3_2_proba_v2\", higher_better=False, number_of_groups=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cat_model2, open(\"../input/ft3_2_cat_model_2.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import math\n",
    "\n",
    "def score_card(prob):\n",
    "    base_score = 600\n",
    "    base_odds = 1/50\n",
    "    PDO = 50\n",
    "    B = PDO*1.0/math.log(2)\n",
    "    A = base_score + B*math.log(base_odds)\n",
    "    return round(A - B*math.log( prob/ (1-prob+1e-20)),0)\n",
    "\n",
    "def lgb_pkl_score(df, model_pkl_path,score_name,predict_pos_neg=1,return_list=[],both_score_with_prob=True):\n",
    "    model = joblib.load(open(model_pkl_path,\"rb\"))\n",
    "    model_features_list = model.feature_name_\n",
    "    df[model_features_list] = df[model_features_list].replace(['none', 'none\\t', -9999, -99, -999, -88888, -99999, -9999999, -2, -1], np.nan)\n",
    "    model_result = df[return_list]\n",
    "    model_result[score_name] = model.predict_proba(df[model_features_list])[:, predict_pos_neg]\n",
    "    if both_score_with_prob:\n",
    "        model_result[score_name.replace(\"prob\",\"score\")] = model_result[score_name].apply(score_card)\n",
    "    return model_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data[['ft_v3_2_quick_prob', 'ft_v3_2_quick_score']] = lgb_pkl_score(df=model_data, model_pkl_path='../model/ft_v3_2_quick.mdl.pkl',score_name='ft_v3_2_quick_prob',predict_pos_neg=1,both_score_with_prob=True).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Count</th>\n",
       "      <th>#Bad</th>\n",
       "      <th>%Bad</th>\n",
       "      <th>%Bad(灰当白)</th>\n",
       "      <th>AUC</th>\n",
       "      <th>KS</th>\n",
       "      <th>AUC(灰当白)</th>\n",
       "      <th>KS(灰当白)</th>\n",
       "      <th>Capture@top10%</th>\n",
       "      <th>Lift@top10%</th>\n",
       "      <th>Lift_Repair@top10%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.Train</th>\n",
       "      <td>63365.0</td>\n",
       "      <td>5796.0</td>\n",
       "      <td>0.120441</td>\n",
       "      <td>0.091470</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.753</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.309</td>\n",
       "      <td>3.09</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.OOT</th>\n",
       "      <td>29918.0</td>\n",
       "      <td>2109.0</td>\n",
       "      <td>0.092642</td>\n",
       "      <td>0.070493</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.268</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          #Count    #Bad      %Bad  %Bad(灰当白)    AUC     KS  AUC(灰当白)  \\\n",
       "source                                                                  \n",
       "0.Train  63365.0  5796.0  0.120441   0.091470  0.772  0.403     0.753   \n",
       "1.OOT    29918.0  2109.0  0.092642   0.070493  0.728  0.330     0.710   \n",
       "\n",
       "         KS(灰当白)  Capture@top10%  Lift@top10%  Lift_Repair@top10%  \n",
       "source                                                             \n",
       "0.Train    0.376           0.309         3.09               3.737  \n",
       "1.OOT      0.304           0.268         2.68               2.994  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def capture_topk(y_ture, y_pred, top=20):\n",
    "    sort_index = np.argsort(-y_pred)\n",
    "    y_ture_sort = y_ture[sort_index]\n",
    "    topk = int(len(y_pred)*top/100)\n",
    "    return np.sum(y_ture_sort[:topk])/np.sum(y_ture_sort)\n",
    "\n",
    "\n",
    "def lift_topk(y_ture, y_pred, top=20):\n",
    "    sort_index = np.argsort(-y_pred)\n",
    "    y_ture_sort = y_ture[sort_index]\n",
    "    topk = int(len(y_pred)*top/100)\n",
    "    return (np.sum(y_ture_sort[:topk])/topk)/(np.sum(y_ture_sort)/len(y_ture))\n",
    "\n",
    "# def lift_repair(data, cut_off, target, score, adjust_bad_rate, adjust_good_rate):\n",
    "#     rj_sample_1 = data.query(f\"{score} < @cut_off and {target}==1\").shape[0]\n",
    "#     rj_sample_0 = data.query(f\"{score} < @cut_off and {target}==0\").shape[0]\n",
    "#     ps_sample_1 = data.query(f\"{score} >= @cut_off and {target}==1\").shape[0]\n",
    "#     ps_sample_0 = data.query(f\"{score} >= @cut_off and {target}==0\").shape[0]\n",
    "#     l = (rj_sample_1/adjust_bad_rate)/(rj_sample_1/adjust_bad_rate+rj_sample_0/adjust_good_rate)*\\\n",
    "#     (1+(rj_sample_0/adjust_good_rate +ps_sample_0/adjust_good_rate)/(rj_sample_1/adjust_bad_rate+ps_sample_1/adjust_bad_rate))\n",
    "#     return l\n",
    "\n",
    "def lift_repair_topk(y_ture, y_pred, adjust_bad_rate, adjust_good_rate, top=20):\n",
    "    sort_index = np.argsort(-y_pred)\n",
    "    y_ture_sort = y_ture[sort_index]\n",
    "    topk = int(len(y_pred)*top/100)\n",
    "    rj_sample_1 = np.sum(y_ture_sort[:topk])\n",
    "    rj_sample_0 = topk - rj_sample_1\n",
    "    ps_sample_1 = np.sum(y_ture_sort[topk:])\n",
    "    ps_sample_0 = len(y_ture_sort[topk:]) - ps_sample_1\n",
    "    return (rj_sample_1/adjust_bad_rate)/(rj_sample_1/adjust_bad_rate+rj_sample_0/adjust_good_rate)*\\\n",
    "    (1+(rj_sample_0/adjust_good_rate +ps_sample_0/adjust_good_rate)/(rj_sample_1/adjust_bad_rate+ps_sample_1/adjust_bad_rate))\n",
    "\n",
    "def f_evalutor(x, proba_name, target):\n",
    "    d = []\n",
    "    d.append(x['cnt'].sum())\n",
    "    d.append(x.query(f\"{target}==[0, 1]\")[target].sum())\n",
    "    d.append(x.query(f\"{target}==[0, 1]\")[target].mean())\n",
    "    d.append(x[target].replace(-1, 0).mean())\n",
    "    d.append(round(roc_auc_score(x.query(f\"{target}!=-1\")[target], x.query(f\"{target}!=-1\")[proba_name]), 3))\n",
    "    d.append(round(ks(x.query(f\"{target}!=-1\")[target], x.query(f\"{target}!=-1\")[proba_name]),3))\n",
    "    d.append(round(roc_auc_score(x[target].replace(-1, 0), x[proba_name]),3))\n",
    "    d.append(round(ks(x[target].replace(-1, 0), x[proba_name]),3))\n",
    "    # capture@top10%\n",
    "    d.append(round(capture_topk(x.query(f\"{target}!=-1\")[target].values, x.query(f\"{target}!=-1\")[proba_name].values, 10), 3))\n",
    "    # lift@top10%\n",
    "    d.append(round(lift_topk(x.query(f\"{target}!=-1\")[target].values, x.query(f\"{target}!=-1\")[proba_name].values, 10), 3))\n",
    "    # lift_repair@top10%\n",
    "    d.append(round(lift_repair_topk(x.query(f\"{target}!=-1\")[target].values, x.query(f\"{target}!=-1\")[proba_name].values, 0.438, 0.16, 10), 3))\n",
    "    return pd.Series(d, index=['#Count', '#Bad', '%Bad', '%Bad(灰当白)', 'AUC', 'KS', 'AUC(灰当白)', 'KS(灰当白)', 'Capture@top10%', 'Lift@top10%', 'Lift_Repair@top10%'])\n",
    "\n",
    "\n",
    "model_data['cnt'] = 1\n",
    "model_data.query(\"dpd30_at_mob6!=-9999\").groupby([\"source\"]).apply(lambda x: f_evalutor(x, \"ft_v3_2_quick_prob\", \"dpd30_at_mob6\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_cols = [x[2:] for x in cat_model2.feature_names_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = \"\"\"\"\"\"\n",
    "result += \"def process(model_data):\\n\"\n",
    "result += \"  import numpy as np\\n\"\n",
    "for col in input_cols:\n",
    "    bins_info_temp = mapiv_temp.query(f\"varname=='{col}'\")\n",
    "    have_null = 1-int(bins_info_temp['bin'].tolist()[0])\n",
    "    # woe transformer\n",
    "    for index, left, right, woe in zip(bins_info_temp['bin'].tolist(), \n",
    "                                bins_info_temp['ll'].tolist(),\n",
    "                                bins_info_temp['ul'].tolist(),\n",
    "                                bins_info_temp['woe'].tolist()):\n",
    "        \n",
    "        if have_null:\n",
    "            if str(left) == \"nan\" and str(right) == \"nan\":\n",
    "                result += f\"  model_data['W_{col}'] = \\\\\\n    np.where(model_data['{col}'].isnull(),     {woe},\\n\"\n",
    "            elif str(right) == \"inf\":\n",
    "                result += f\"  {woe}\" + \")\"*int(index) + \"\\n\\n\"\n",
    "            else:\n",
    "                result += f\"    np.where(model_data['{col}'] < {right},        {woe},\\n\"\n",
    "        else:\n",
    "            if int(index)==1:\n",
    "                result += f\"  model_data['W_{col}'] = \\\\\\n    np.where(model_data['{col}'] <{right},     {woe},\\n\"\n",
    "            elif str(right) == \"inf\":\n",
    "                result += f\"  {woe}\" + \")\"*(int(index)-1) + \"\\n\\n\"\n",
    "            else:\n",
    "                result += f\"    np.where(model_data['{col}'] < {right},        {woe},\\n\"\n",
    "            \n",
    "result += \"  return model_data\"\n",
    " \n",
    "print(result, file=open(\"condition_calculate_mob6_input_v2.py\", \"w+\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W_wb_v2_0_prob',\n",
       " 'W_dxm_general_fraudc_v3_score',\n",
       " 'W_limit_used_rate',\n",
       " 'W_bw_b_score_v3',\n",
       " 'W_tx_riskscore',\n",
       " 'W_age',\n",
       " 'W_ppde_7d_itfin_cashloan_cnt',\n",
       " 'W_ppde_30d_itfin_cashloan_cnt',\n",
       " 'W_diff_pass_credit_first_loan_time',\n",
       " 'W_idcardpre6',\n",
       " 'W_jd_ppre_debit_level',\n",
       " 'W_als_m3_id_nbank_nsloan_orgnum',\n",
       " 'W_als_m12_id_nbank_cons_allnum',\n",
       " 'W_als_m1_cell_nbank_selfnum',\n",
       " 'W_als_m3_id_rel_allnum',\n",
       " 'W_loan_term6_apply_count',\n",
       " 'W_youmeng_bank_score',\n",
       " 'W_als_m6_id_nbank_nsloan_orgnum',\n",
       " 'W_jd_ppre_credit_asst_level',\n",
       " 'W_als_m1_id_nbank_selfnum',\n",
       " 'W_als_m1_id_nbank_nsloan_allnum',\n",
       " 'W_als_m3_id_min_inteday',\n",
       " 'W_als_m6_id_min_monnum',\n",
       " 'W_als_m12_cell_nbank_cons_allnum',\n",
       " 'W_als_m6_id_bank_tot_mons',\n",
       " 'W_als_m3_id_nbank_min_inteday',\n",
       " 'W_ronghui_p_ft_p0136',\n",
       " 'W_gender',\n",
       " 'W_ppde_60d_itfin_cashloan_cnt',\n",
       " 'W_ppde_3d_itfin_cashloan_cnt',\n",
       " 'W_als_m3_id_nbank_sloan_allnum',\n",
       " 'W_als_m3_cell_min_inteday',\n",
       " 'W_als_m12_id_nbank_week_orgnum',\n",
       " 'W_als_m6_id_nbank_cons_allnum',\n",
       " 'W_als_m6_id_bank_tra_allnum',\n",
       " 'W_als_m3_cell_nbank_sloan_allnum',\n",
       " 'W_als_m12_id_bank_orgnum',\n",
       " 'W_ronghui_p_ft_p0301',\n",
       " 'W_als_m6_cell_nbank_oth_orgnum',\n",
       " 'W_ronghui_p_ft_p0040',\n",
       " 'W_ppde_7d_itfin_cnt',\n",
       " 'W_als_m3_cell_nbank_nsloan_orgnum',\n",
       " 'W_ronghui_p_ft_p0113',\n",
       " 'W_als_m1_id_nbank_orgnum',\n",
       " 'W_als_m6_id_caon_orgnum',\n",
       " 'W_als_m12_id_nbank_nsloan_orgnum',\n",
       " 'W_jd_ppre_intst_rate_sens_level',\n",
       " 'W_loan_hour12_apply_count',\n",
       " 'W_als_m3_id_nbank_nsloan_allnum',\n",
       " 'W_recent_reject_to_now_days',\n",
       " 'W_als_m6_cell_nbank_nsloan_orgnum',\n",
       " 'W_ppde_30d_itfin_cnt',\n",
       " 'W_als_m6_id_nbank_else_allnum',\n",
       " 'W_als_m12_id_nbank_nsloan_allnum',\n",
       " 'W_als_m12_id_nbank_ca_allnum',\n",
       " 'W_als_m12_id_bank_tra_orgnum',\n",
       " 'W_als_m3_id_nbank_min_monnum',\n",
       " 'W_als_m6_id_nbank_week_orgnum',\n",
       " 'W_als_m1_id_nbank_oth_orgnum',\n",
       " 'W_wb_v2_0_confidence',\n",
       " 'W_als_m3_id_nbank_ca_allnum',\n",
       " 'W_als_m3_id_nbank_selfnum',\n",
       " 'W_ronghui_p_ft_p0189',\n",
       " 'W_als_m12_id_nbank_else_orgnum',\n",
       " 'W_als_m1_id_rel_allnum',\n",
       " 'W_als_m3_cell_rel_allnum',\n",
       " 'W_ronghui_p_ft_p0057',\n",
       " 'W_als_m3_id_max_monnum',\n",
       " 'W_als_m12_cell_rel_allnum',\n",
       " 'W_loan_apply_count',\n",
       " 'W_als_m6_cell_nbank_min_inteday',\n",
       " 'W_als_m6_id_nbank_orgnum',\n",
       " 'W_als_m3_id_nbank_cf_allnum',\n",
       " 'W_als_m6_cell_nbank_orgnum',\n",
       " 'W_als_m12_id_max_inteday',\n",
       " 'W_als_m6_cell_min_inteday',\n",
       " 'W_als_m12_id_nbank_cf_orgnum',\n",
       " 'W_als_m3_id_nbank_orgnum',\n",
       " 'W_als_m6_id_avg_monnum',\n",
       " 'W_als_m6_id_nbank_nsloan_allnum']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data[['loan_id', 'ft3_2_proba_v2']].to_csv(\"../output/ft3_2_model_data_ft3_2_score_v2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train=train, valid=validation, oot=oot_sample1, sel_cols = sel_cols, target=target):\n",
    "    cat_params = {\n",
    "        'eval_metric':'AUC',\n",
    "        'objective': 'CrossEntropy', \n",
    "        'bootstrap_type': trial.suggest_categorical('bootstrap_type', ['Bernoulli']),\n",
    "        'loss_function' : FocalLossObjective(),\n",
    "        'od_wait': trial.suggest_int('od_wait', 3, 10),\n",
    "        'random_strength':trial.suggest_categorical('random_strength', [4, 5, 6]),\n",
    "        'max_bin': trial.suggest_int('max_bin', 2, 8),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.88, 0.99),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.05]),\n",
    "        'leaf_estimation_iterations':trial.suggest_int('leaf_estimation_iterations', 3, 10),\n",
    "        'iterations':  400,\n",
    "        'depth': trial.suggest_categorical('depth', [4]),\n",
    "        'random_seed': trial.suggest_categorical('random_state', [42, 2023]),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 200, 500),\n",
    "    }\n",
    "    cat_model = CatBoostClassifier(**cat_params)\n",
    "    \n",
    "    cat_model.fit(train[sel_cols], train[target], eval_set=[(train[sel_cols], train[target]), (oot_sample1[sel_cols], oot_sample1[target])],\n",
    "             early_stopping_rounds=20, verbose=False)   \n",
    "    oot['proba'] = cat_model.predict_proba(oot_sample1[sel_cols])[:,1]\n",
    "    \n",
    "    auc_score = lift_topk(oot[target].values, oot[\"proba\"].values, 10)\n",
    "    return auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-11 12:50:12,938]\u001b[0m A new study created in memory with name: no-name-d93631e0-7072-4901-b279-721b7d93956e\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:16,214]\u001b[0m Trial 0 finished with value: 2.869288329120907 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 9, 'subsample': 0.9340242322921329, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 310}. Best is trial 0 with value: 2.869288329120907.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:22,042]\u001b[0m Trial 1 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 6, 'reg_lambda': 10, 'subsample': 0.956889286054307, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 440}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:24,889]\u001b[0m Trial 2 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 4, 'max_bin': 4, 'reg_lambda': 2, 'subsample': 0.9318812394674577, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 436}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:27,683]\u001b[0m Trial 3 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9091433283433743, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 450}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:31,072]\u001b[0m Trial 4 finished with value: 2.831347326421788 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 4, 'max_bin': 4, 'reg_lambda': 5, 'subsample': 0.9753587494231943, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 468}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:34,442]\u001b[0m Trial 5 finished with value: 2.8028915743974476 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 6, 'max_bin': 2, 'reg_lambda': 8, 'subsample': 0.9231301312896356, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 203}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:37,842]\u001b[0m Trial 6 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 6, 'max_bin': 6, 'reg_lambda': 6, 'subsample': 0.9845615870775415, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:41,199]\u001b[0m Trial 7 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 6, 'reg_lambda': 3, 'subsample': 0.9411807164836173, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 344}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:44,272]\u001b[0m Trial 8 finished with value: 2.8550604531087367 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 5, 'subsample': 0.9809119185762711, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 349}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:47,579]\u001b[0m Trial 9 finished with value: 2.831347326421788 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 3, 'reg_lambda': 3, 'subsample': 0.9256895195973641, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 216}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:50,888]\u001b[0m Trial 10 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 7, 'subsample': 0.8830146513000773, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 407}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:54,269]\u001b[0m Trial 11 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 10, 'subsample': 0.9605592725762861, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 485}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:50:57,508]\u001b[0m Trial 12 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 6, 'max_bin': 6, 'reg_lambda': 6, 'subsample': 0.960371025371225, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 395}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:01,079]\u001b[0m Trial 13 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 6, 'reg_lambda': 10, 'subsample': 0.9867652443703064, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:04,928]\u001b[0m Trial 14 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9618518869913943, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:08,216]\u001b[0m Trial 15 finished with value: 2.8645457037835165 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 7, 'subsample': 0.9462003272244003, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 409}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:11,826]\u001b[0m Trial 16 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 4, 'reg_lambda': 8, 'subsample': 0.9730988603081684, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 300}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:15,103]\u001b[0m Trial 17 finished with value: 2.8550604531087367 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 6, 'max_bin': 6, 'reg_lambda': 9, 'subsample': 0.9501715700217666, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 437}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:21,229]\u001b[0m Trial 18 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 4, 'max_bin': 5, 'reg_lambda': 6, 'subsample': 0.9675204953086416, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 379}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:24,897]\u001b[0m Trial 19 finished with value: 2.874030954458297 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 7, 'subsample': 0.9898623675893535, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 459}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:27,996]\u001b[0m Trial 20 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 4, 'subsample': 0.9518368457104099, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 258}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:31,324]\u001b[0m Trial 21 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 7, 'subsample': 0.8801561077349455, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 414}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:34,808]\u001b[0m Trial 22 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 8, 'subsample': 0.8815797225066623, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 378}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:38,151]\u001b[0m Trial 23 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 9, 'subsample': 0.9031147461287524, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 433}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:41,641]\u001b[0m Trial 24 finished with value: 2.8645457037835165 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8939839714963059, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 476}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:45,161]\u001b[0m Trial 25 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 4, 'max_bin': 6, 'reg_lambda': 10, 'subsample': 0.9136911458830821, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 417}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:48,833]\u001b[0m Trial 26 finished with value: 2.878773579795687 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 5, 'subsample': 0.8898969469772474, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 382}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:52,109]\u001b[0m Trial 27 finished with value: 2.783921073047888 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 6, 'max_bin': 3, 'reg_lambda': 7, 'subsample': 0.9773596362391803, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 459}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:54,841]\u001b[0m Trial 28 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 6, 'reg_lambda': 8, 'subsample': 0.9204221700055915, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:51:57,973]\u001b[0m Trial 29 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 9, 'subsample': 0.9372033825486451, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 325}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:00,982]\u001b[0m Trial 30 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 6, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9670170581942753, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 444}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:03,923]\u001b[0m Trial 31 finished with value: 2.869288329120907 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 9, 'subsample': 0.9360232023322549, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 319}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:07,664]\u001b[0m Trial 32 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 10, 'subsample': 0.9580478060189282, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 482}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:10,886]\u001b[0m Trial 33 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 5, 'max_bin': 4, 'reg_lambda': 9, 'subsample': 0.939104780856508, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 323}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:14,301]\u001b[0m Trial 34 finished with value: 2.8598030784461272 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 8, 'subsample': 0.9301626475293311, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 277}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:20,426]\u001b[0m Trial 35 finished with value: 2.874030954458297 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 3, 'reg_lambda': 9, 'subsample': 0.9164433378994278, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 367}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:23,676]\u001b[0m Trial 36 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 5, 'max_bin': 4, 'reg_lambda': 6, 'subsample': 0.9021704207494202, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 424}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:27,812]\u001b[0m Trial 37 finished with value: 2.8645457037835165 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 10, 'subsample': 0.9823794687566894, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 467}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:31,577]\u001b[0m Trial 38 finished with value: 2.878773579795687 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 7, 'subsample': 0.9298022589572834, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 334}. Best is trial 1 with value: 2.935685083844366.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:34,916]\u001b[0m Trial 39 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 9, 'subsample': 0.9444159531821086, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 398}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:38,085]\u001b[0m Trial 40 finished with value: 2.798148949060058 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 2, 'reg_lambda': 5, 'subsample': 0.9478810622559524, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 395}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:42,635]\u001b[0m Trial 41 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 8, 'subsample': 0.9431090884093998, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 362}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:45,784]\u001b[0m Trial 42 finished with value: 2.8645457037835165 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 9, 'subsample': 0.9531432734637947, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 401}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:48,687]\u001b[0m Trial 43 finished with value: 2.8598030784461272 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 6, 'max_bin': 4, 'reg_lambda': 10, 'subsample': 0.9341742864943887, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 300}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:51,742]\u001b[0m Trial 44 finished with value: 2.8598030784461272 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 6, 'max_bin': 6, 'reg_lambda': 10, 'subsample': 0.9550402452440879, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 351}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:54,857]\u001b[0m Trial 45 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 8, 'subsample': 0.9251512684779215, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 451}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:52:57,828]\u001b[0m Trial 46 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 9, 'subsample': 0.9434724522705289, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 427}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:01,354]\u001b[0m Trial 47 finished with value: 2.8550604531087367 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 10, 'subsample': 0.9659011414601292, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 484}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:04,530]\u001b[0m Trial 48 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 5, 'reg_lambda': 3, 'subsample': 0.9725828015562482, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 394}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:07,575]\u001b[0m Trial 49 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 4, 'max_bin': 6, 'reg_lambda': 7, 'subsample': 0.9461959057817502, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 363}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:10,858]\u001b[0m Trial 50 finished with value: 2.845575202433957 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 6, 'max_bin': 4, 'reg_lambda': 6, 'subsample': 0.9373762596113117, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 344}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:14,066]\u001b[0m Trial 51 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 10, 'subsample': 0.9597412381164782, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:20,064]\u001b[0m Trial 52 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 6, 'reg_lambda': 9, 'subsample': 0.9711406822735131, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 445}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:23,316]\u001b[0m Trial 53 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 10, 'subsample': 0.9808540822194334, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 469}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:26,487]\u001b[0m Trial 54 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 9, 'subsample': 0.9617929898617411, 'learning_rate': 0.05, 'leaf_estimation_iterations': 9, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 459}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:29,732]\u001b[0m Trial 55 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 5, 'reg_lambda': 8, 'subsample': 0.9546851726358577, 'learning_rate': 0.05, 'leaf_estimation_iterations': 10, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 409}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:32,779]\u001b[0m Trial 56 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9411316675854439, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 476}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:35,347]\u001b[0m Trial 57 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 3, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9307178469435026, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:37,966]\u001b[0m Trial 58 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 4, 'subsample': 0.941180449555782, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 435}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:40,919]\u001b[0m Trial 59 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9217020446174019, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 468}. Best is trial 39 with value: 2.945170334519146.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:43,427]\u001b[0m Trial 60 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8926008976798605, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 468}. Best is trial 60 with value: 2.9546555851939256.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:46,073]\u001b[0m Trial 61 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8870263471915303, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 468}. Best is trial 60 with value: 2.9546555851939256.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:48,508]\u001b[0m Trial 62 finished with value: 2.973626086543485 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8877390866014263, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 467}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:50,944]\u001b[0m Trial 63 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8861543416148514, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 465}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:53,471]\u001b[0m Trial 64 finished with value: 2.874030954458297 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8968903002251511, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 452}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:55,946]\u001b[0m Trial 65 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 3, 'subsample': 0.8862509426391643, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 495}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:53:58,338]\u001b[0m Trial 66 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 2, 'subsample': 0.8862654330532309, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:00,882]\u001b[0m Trial 67 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8923434212397179, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 488}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:03,400]\u001b[0m Trial 68 finished with value: 2.8550604531087367 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.9002523146005658, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 440}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:05,938]\u001b[0m Trial 69 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.9087988814053407, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 498}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:08,639]\u001b[0m Trial 70 finished with value: 2.8503178277713475 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9073583100342479, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 476}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:11,171]\u001b[0m Trial 71 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8854361858807674, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 457}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:13,591]\u001b[0m Trial 72 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.9071060226693821, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 467}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:16,324]\u001b[0m Trial 73 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.8902978868604317, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:22,249]\u001b[0m Trial 74 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.912305463886591, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 499}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:24,807]\u001b[0m Trial 75 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.8896151095350395, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 486}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:27,686]\u001b[0m Trial 76 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8946689690375694, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:30,606]\u001b[0m Trial 77 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 1, 'subsample': 0.8996161208674426, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 420}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:33,604]\u001b[0m Trial 78 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8902843555069413, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 473}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:36,515]\u001b[0m Trial 79 finished with value: 2.869288329120907 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9045197016392883, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 431}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:39,815]\u001b[0m Trial 80 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 1, 'subsample': 0.9208483370983978, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 446}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:43,869]\u001b[0m Trial 81 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 2, 'subsample': 0.8855169879826218, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 491}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:46,841]\u001b[0m Trial 82 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 3, 'subsample': 0.8814558352173787, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 462}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:49,593]\u001b[0m Trial 83 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.8874455996399072, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 479}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:52,260]\u001b[0m Trial 84 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8977451287684818, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 495}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:54,806]\u001b[0m Trial 85 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 1, 'subsample': 0.9219593051163439, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 446}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:54:57,403]\u001b[0m Trial 86 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8829654118636561, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 482}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:00,069]\u001b[0m Trial 87 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9169532084836414, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 453}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:02,936]\u001b[0m Trial 88 finished with value: 2.8598030784461272 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9101074549971382, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 453}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:05,883]\u001b[0m Trial 89 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 6, 'reg_lambda': 5, 'subsample': 0.9188089368200307, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 471}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:08,711]\u001b[0m Trial 90 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9259204386686626, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 463}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:11,682]\u001b[0m Trial 91 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9251902710049956, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 482}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:14,794]\u001b[0m Trial 92 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9242204636444591, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 462}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:20,883]\u001b[0m Trial 93 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.8905106370512579, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:24,564]\u001b[0m Trial 94 finished with value: 2.878773579795687 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9289786416897442, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 483}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:27,533]\u001b[0m Trial 95 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 6, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.9264371388909678, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 463}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:31,069]\u001b[0m Trial 96 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.9328004653075995, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 474}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:34,741]\u001b[0m Trial 97 finished with value: 2.878773579795687 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9143813177076959, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 441}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:38,440]\u001b[0m Trial 98 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 1, 'subsample': 0.9201707268079685, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 211}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:42,107]\u001b[0m Trial 99 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9254630253295113, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 458}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:45,392]\u001b[0m Trial 100 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8942198631586359, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 236}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:48,551]\u001b[0m Trial 101 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 2, 'subsample': 0.8834286855750996, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 469}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:51,545]\u001b[0m Trial 102 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 3, 'subsample': 0.8884874114700075, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 495}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:54,550]\u001b[0m Trial 103 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9187709312106828, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 486}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:55:57,401]\u001b[0m Trial 104 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9185673321592106, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 484}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:00,564]\u001b[0m Trial 105 finished with value: 2.8550604531087367 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9102107092838232, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:04,063]\u001b[0m Trial 106 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9278097386201597, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:07,205]\u001b[0m Trial 107 finished with value: 2.8882588304704666 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.9228912814605726, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 448}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:10,576]\u001b[0m Trial 108 finished with value: 2.874030954458297 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8926687795664183, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 472}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:13,466]\u001b[0m Trial 109 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.9143197250799721, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:16,464]\u001b[0m Trial 110 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 1, 'subsample': 0.9187429823162682, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 457}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:21,890]\u001b[0m Trial 111 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 7, 'reg_lambda': 1, 'subsample': 0.923434702205975, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 464}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:24,796]\u001b[0m Trial 112 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 5, 'reg_lambda': 2, 'subsample': 0.9326233766802408, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 485}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:27,729]\u001b[0m Trial 113 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8947848262015293, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 308}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:30,677]\u001b[0m Trial 114 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.9045613162149198, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 270}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:33,508]\u001b[0m Trial 115 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 1, 'subsample': 0.9160923144737159, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 295}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:36,774]\u001b[0m Trial 116 finished with value: 2.783921073047888 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 6, 'max_bin': 2, 'reg_lambda': 2, 'subsample': 0.9280224553631999, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 371}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:39,923]\u001b[0m Trial 117 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8954242116847886, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 492}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:42,784]\u001b[0m Trial 118 finished with value: 2.8266047010843973 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.898473118909143, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 333}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:45,866]\u001b[0m Trial 119 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8967713662183183, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:48,946]\u001b[0m Trial 120 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8954363593104226, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:52,071]\u001b[0m Trial 121 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8952380608197164, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 491}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:55,125]\u001b[0m Trial 122 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9018744866201673, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 486}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:56:57,999]\u001b[0m Trial 123 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8917664594589321, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 471}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:01,078]\u001b[0m Trial 124 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8887831883384898, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 307}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:04,038]\u001b[0m Trial 125 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.895215809585487, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 480}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:07,187]\u001b[0m Trial 126 finished with value: 2.8076341997348377 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 3, 'reg_lambda': 5, 'subsample': 0.9007935788554545, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:10,246]\u001b[0m Trial 127 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 9, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.8845643628842302, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 385}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:13,087]\u001b[0m Trial 128 finished with value: 2.973626086543485 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8921583366339976, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 495}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:15,926]\u001b[0m Trial 129 finished with value: 2.8882588304704666 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8927873085796355, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 289}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:21,369]\u001b[0m Trial 130 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8908888067933285, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 356}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:24,495]\u001b[0m Trial 131 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8959344563720002, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:27,424]\u001b[0m Trial 132 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.880087049557662, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:30,341]\u001b[0m Trial 133 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8967175708100457, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 487}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:33,107]\u001b[0m Trial 134 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8876322264795286, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 496}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:36,015]\u001b[0m Trial 135 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.906056670163393, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 491}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:38,851]\u001b[0m Trial 136 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8871367078342994, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 483}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:42,067]\u001b[0m Trial 137 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8925376837845158, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 468}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:44,968]\u001b[0m Trial 138 finished with value: 2.878773579795687 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8990371505020054, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 477}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:47,458]\u001b[0m Trial 139 finished with value: 2.836089951759177 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8888888353349217, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 482}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:50,588]\u001b[0m Trial 140 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 5, 'subsample': 0.9495198408745109, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 473}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:53,342]\u001b[0m Trial 141 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8825811461629508, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 495}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:56,530]\u001b[0m Trial 142 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 5, 'subsample': 0.9484492224635065, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 474}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:57:59,879]\u001b[0m Trial 143 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 5, 'subsample': 0.9459692720011835, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 466}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:03,077]\u001b[0m Trial 144 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.9502411093562667, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 488}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:06,415]\u001b[0m Trial 145 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8947751573424707, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 486}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:09,301]\u001b[0m Trial 146 finished with value: 2.836089951759177 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8946937819090489, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 487}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:12,165]\u001b[0m Trial 147 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8873908691522298, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:15,107]\u001b[0m Trial 148 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8906602463841424, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 488}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:20,722]\u001b[0m Trial 149 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.951687376767792, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:23,135]\u001b[0m Trial 150 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8897757489910687, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:25,630]\u001b[0m Trial 151 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8867073610722225, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 483}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:28,024]\u001b[0m Trial 152 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.886751213263165, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:30,486]\u001b[0m Trial 153 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8915812334515593, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 485}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:32,900]\u001b[0m Trial 154 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8849315961740417, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:35,367]\u001b[0m Trial 155 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8840375341813573, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:37,746]\u001b[0m Trial 156 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8962143562913807, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:40,233]\u001b[0m Trial 157 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8845948480835012, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 499}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:42,662]\u001b[0m Trial 158 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8818888038406314, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:45,094]\u001b[0m Trial 159 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8838943025012759, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:47,548]\u001b[0m Trial 160 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8806037239030189, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 496}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:49,955]\u001b[0m Trial 161 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8859540506608601, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 481}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:52,443]\u001b[0m Trial 162 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8883868530718985, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:54,865]\u001b[0m Trial 163 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8883688861431059, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 482}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:57,267]\u001b[0m Trial 164 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8823139651011006, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 487}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:58:59,677]\u001b[0m Trial 165 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8934286523140543, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 488}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:02,139]\u001b[0m Trial 166 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8933864953647115, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:04,513]\u001b[0m Trial 167 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.890863762010192, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 476}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:07,119]\u001b[0m Trial 168 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8927488546942414, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:09,605]\u001b[0m Trial 169 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8984011026721933, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:12,112]\u001b[0m Trial 170 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8852731531463429, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 499}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:14,726]\u001b[0m Trial 171 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8879879242839488, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 481}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:19,793]\u001b[0m Trial 172 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8933860008916721, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 483}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:23,277]\u001b[0m Trial 173 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8899661618080854, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 497}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:25,739]\u001b[0m Trial 174 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8935395928229877, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:28,128]\u001b[0m Trial 175 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8906071461058865, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:30,550]\u001b[0m Trial 176 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8847408333076556, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 243}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:32,941]\u001b[0m Trial 177 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8828330766127601, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 233}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:35,339]\u001b[0m Trial 178 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8889082068471909, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 220}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:37,733]\u001b[0m Trial 179 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8846603974747397, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 265}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:40,247]\u001b[0m Trial 180 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8867914814375653, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 243}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:42,620]\u001b[0m Trial 181 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8812831710185315, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 241}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:45,099]\u001b[0m Trial 182 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8865204353153621, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 257}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:47,510]\u001b[0m Trial 183 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8848792874278203, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 265}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:49,890]\u001b[0m Trial 184 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8867207892873763, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:52,309]\u001b[0m Trial 185 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8918306315817123, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:54,845]\u001b[0m Trial 186 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8834511161594399, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:57,241]\u001b[0m Trial 187 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8801449069680969, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 258}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 12:59:59,680]\u001b[0m Trial 188 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8898895475101335, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 246}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:02,122]\u001b[0m Trial 189 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8869314959892403, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 230}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:04,515]\u001b[0m Trial 190 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.891250266505947, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 263}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:07,010]\u001b[0m Trial 191 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.892557401163485, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 234}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:09,399]\u001b[0m Trial 192 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8912617096172246, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 273}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:12,009]\u001b[0m Trial 193 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8867782875129209, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:14,528]\u001b[0m Trial 194 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8887723405782763, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 243}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:18,710]\u001b[0m Trial 195 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8846311907833337, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 221}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:23,330]\u001b[0m Trial 196 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8888808952166896, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 257}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:26,132]\u001b[0m Trial 197 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8830056817876022, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 263}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:29,098]\u001b[0m Trial 198 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8968360848690252, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 239}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:32,264]\u001b[0m Trial 199 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8855640668729505, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 256}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:37,565]\u001b[0m Trial 200 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8855662966686858, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 226}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:40,304]\u001b[0m Trial 201 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.888761154547295, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:43,075]\u001b[0m Trial 202 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8855979421196907, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 281}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:45,891]\u001b[0m Trial 203 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8826483427463493, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 256}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:51,818]\u001b[0m Trial 204 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8941926801476611, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 267}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:54,260]\u001b[0m Trial 205 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8906417193608094, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 260}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:00:57,251]\u001b[0m Trial 206 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.887836559271833, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 245}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:00,221]\u001b[0m Trial 207 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.9648686519575702, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 256}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:05,914]\u001b[0m Trial 208 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 7, 'subsample': 0.8874879824200846, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 242}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:08,820]\u001b[0m Trial 209 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8843339285902632, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 244}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:11,762]\u001b[0m Trial 210 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8919024878326446, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 281}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:14,806]\u001b[0m Trial 211 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8887174659186903, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 248}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:19,823]\u001b[0m Trial 212 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 7, 'subsample': 0.8867578238735448, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 256}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:23,456]\u001b[0m Trial 213 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.882258818833754, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 273}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:26,238]\u001b[0m Trial 214 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8900073083110666, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 310}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:29,140]\u001b[0m Trial 215 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8945243536695103, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 249}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:33,950]\u001b[0m Trial 216 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8852903136774924, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 256}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:38,540]\u001b[0m Trial 217 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8879303395026842, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 332}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:41,417]\u001b[0m Trial 218 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8800771885370265, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 244}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:44,148]\u001b[0m Trial 219 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8915546015451989, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 238}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:48,482]\u001b[0m Trial 220 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8972599761407815, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:53,491]\u001b[0m Trial 221 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8885279482830585, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 496}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:56,531]\u001b[0m Trial 222 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8865949207332439, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 260}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:01:59,701]\u001b[0m Trial 223 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8840689377183987, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 204}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:05,033]\u001b[0m Trial 224 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8859682163457913, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 343}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:08,674]\u001b[0m Trial 225 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.893073626922886, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 262}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:11,832]\u001b[0m Trial 226 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8895699999248209, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 267}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:14,967]\u001b[0m Trial 227 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8865846995291589, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 255}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:20,165]\u001b[0m Trial 228 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8869967037358223, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 257}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:23,572]\u001b[0m Trial 229 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8906693915280611, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 230}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:26,628]\u001b[0m Trial 230 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8822719723311993, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 254}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:29,791]\u001b[0m Trial 231 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8849656326130558, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 246}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:35,689]\u001b[0m Trial 232 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8871411341804786, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 263}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:38,965]\u001b[0m Trial 233 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8837350346363079, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 238}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:41,760]\u001b[0m Trial 234 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8827160378013975, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 245}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:44,245]\u001b[0m Trial 235 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8854574732656578, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 270}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:46,803]\u001b[0m Trial 236 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9571073767528838, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:53,619]\u001b[0m Trial 237 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8839751092213047, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 233}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:56,260]\u001b[0m Trial 238 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 7, 'subsample': 0.8816892471104592, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 240}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:02:59,015]\u001b[0m Trial 239 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8889520653968295, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 247}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:01,800]\u001b[0m Trial 240 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8869466594102419, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 236}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:08,244]\u001b[0m Trial 241 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8916891245411893, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 254}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:11,482]\u001b[0m Trial 242 finished with value: 2.869288329120907 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 4, 'reg_lambda': 4, 'subsample': 0.8937466481476388, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 260}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:14,445]\u001b[0m Trial 243 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8897768795282148, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 316}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:18,198]\u001b[0m Trial 244 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8954884559035092, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 492}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:23,045]\u001b[0m Trial 245 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8846818682176328, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 485}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:25,542]\u001b[0m Trial 246 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8837061593417476, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:28,023]\u001b[0m Trial 247 finished with value: 2.798148949060058 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 3, 'reg_lambda': 4, 'subsample': 0.885936363211023, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 484}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:30,716]\u001b[0m Trial 248 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8811579061713468, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 474}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:36,542]\u001b[0m Trial 249 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 5, 'subsample': 0.889013493070697, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 226}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:39,177]\u001b[0m Trial 250 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.890988360164205, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:41,802]\u001b[0m Trial 251 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8929174454044541, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:44,430]\u001b[0m Trial 252 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9768596617008173, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 483}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:46,931]\u001b[0m Trial 253 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8844766709034027, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 241}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:52,569]\u001b[0m Trial 254 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8874727369499152, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 248}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:55,413]\u001b[0m Trial 255 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 6, 'subsample': 0.8906549604538481, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:03:58,192]\u001b[0m Trial 256 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8873933232573028, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 259}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:01,342]\u001b[0m Trial 257 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8957447861641659, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:06,964]\u001b[0m Trial 258 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8844574467232996, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 238}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:10,405]\u001b[0m Trial 259 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8903112669909289, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 268}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:13,582]\u001b[0m Trial 260 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8883283033519743, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:16,629]\u001b[0m Trial 261 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8926879751159605, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 254}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:22,319]\u001b[0m Trial 262 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 6, 'subsample': 0.894366661581199, 'learning_rate': 0.05, 'leaf_estimation_iterations': 7, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 286}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:25,141]\u001b[0m Trial 263 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9700415563358326, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 245}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:27,888]\u001b[0m Trial 264 finished with value: 2.8503178277713475 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8986617767433238, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 302}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:30,651]\u001b[0m Trial 265 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8831473051877982, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 262}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:34,920]\u001b[0m Trial 266 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8862507038309647, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:38,706]\u001b[0m Trial 267 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8856554792761294, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 495}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:41,512]\u001b[0m Trial 268 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8915697171003523, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 277}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:44,240]\u001b[0m Trial 269 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.8899570528567956, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:47,208]\u001b[0m Trial 270 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.881284568936118, 'learning_rate': 0.05, 'leaf_estimation_iterations': 5, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 487}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:52,980]\u001b[0m Trial 271 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8836743352162043, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:56,046]\u001b[0m Trial 272 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 7, 'subsample': 0.8802999573165694, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 490}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:04:58,851]\u001b[0m Trial 273 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8880566541573245, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 251}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:01,696]\u001b[0m Trial 274 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8865852858611424, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 260}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:07,313]\u001b[0m Trial 275 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8860641492791278, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 267}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:10,159]\u001b[0m Trial 276 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8874944952909417, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 484}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:12,945]\u001b[0m Trial 277 finished with value: 2.878773579795687 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8910237229342428, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 241}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:15,690]\u001b[0m Trial 278 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.8887782923973218, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 472}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:20,279]\u001b[0m Trial 279 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8919662063252298, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 256}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:24,710]\u001b[0m Trial 280 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8859698098092764, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 250}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:27,199]\u001b[0m Trial 281 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8873927049344789, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 261}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:30,155]\u001b[0m Trial 282 finished with value: 2.8503178277713475 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8826346793573052, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 485}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:33,739]\u001b[0m Trial 283 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8966184171594755, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 491}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:38,893]\u001b[0m Trial 284 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8848673536525975, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 496}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:42,301]\u001b[0m Trial 285 finished with value: 2.926199833169586 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 5, 'random_strength': 4, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8829693575609175, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 497}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:45,752]\u001b[0m Trial 286 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 5, 'subsample': 0.8853540424898495, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 259}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:50,200]\u001b[0m Trial 287 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8840719995023963, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:54,265]\u001b[0m Trial 288 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8822970796736114, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:05:57,326]\u001b[0m Trial 289 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8886381297660251, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 489}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:01,344]\u001b[0m Trial 290 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8932340154446811, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:06,269]\u001b[0m Trial 291 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8844058135486593, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 491}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:09,166]\u001b[0m Trial 292 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8898755748030392, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 273}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:11,826]\u001b[0m Trial 293 finished with value: 2.921457207832196 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.9406436049991764, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:14,573]\u001b[0m Trial 294 finished with value: 2.8977440811452464 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 4, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 2, 'subsample': 0.8806473309237424, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 496}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:17,630]\u001b[0m Trial 295 finished with value: 2.9593982105313157 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 4, 'subsample': 0.937703084883132, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 481}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:23,617]\u001b[0m Trial 296 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 4, 'subsample': 0.8843575071451266, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 255}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:27,632]\u001b[0m Trial 297 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 4, 'subsample': 0.9881807951594942, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:30,821]\u001b[0m Trial 298 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 4, 'subsample': 0.9341058473695404, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 404}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:36,121]\u001b[0m Trial 299 finished with value: 2.9167145824948064 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.9553305407852083, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 487}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:40,294]\u001b[0m Trial 300 finished with value: 2.8645457037835165 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 2, 'subsample': 0.9455459689347, 'learning_rate': 0.05, 'leaf_estimation_iterations': 8, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 477}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:43,888]\u001b[0m Trial 301 finished with value: 2.8645457037835165 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 10, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.8863657385157453, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 42, 'min_data_in_leaf': 385}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:47,091]\u001b[0m Trial 302 finished with value: 2.874030954458297 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.9369095110797868, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 494}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:52,759]\u001b[0m Trial 303 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8869920632842876, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 237}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:55,919]\u001b[0m Trial 304 finished with value: 2.930942458506976 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8822132881560778, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 229}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:06:59,004]\u001b[0m Trial 305 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 6, 'subsample': 0.8894960860184923, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 478}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:02,147]\u001b[0m Trial 306 finished with value: 2.8930014558078567 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 4, 'max_bin': 5, 'reg_lambda': 4, 'subsample': 0.9514839935791654, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 486}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:07,936]\u001b[0m Trial 307 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8835338601595347, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 493}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:11,107]\u001b[0m Trial 308 finished with value: 2.949912959856536 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 3, 'subsample': 0.8863747445616016, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 479}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:14,074]\u001b[0m Trial 309 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 6, 'reg_lambda': 5, 'subsample': 0.8802717570755544, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 482}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:17,284]\u001b[0m Trial 310 finished with value: 2.9024867064826365 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 6, 'random_strength': 6, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8890910060383103, 'learning_rate': 0.05, 'leaf_estimation_iterations': 4, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 264}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:23,239]\u001b[0m Trial 311 finished with value: 2.9072293318200266 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 4, 'subsample': 0.9601598828853523, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 500}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:26,694]\u001b[0m Trial 312 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 7, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8921772437848425, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 325}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:30,149]\u001b[0m Trial 313 finished with value: 2.9688834612060955 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8918259510406483, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 417}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:33,233]\u001b[0m Trial 314 finished with value: 2.945170334519146 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 7, 'reg_lambda': 3, 'subsample': 0.8919671399269437, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 410}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:39,111]\u001b[0m Trial 315 finished with value: 2.9641408358687054 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8948084037143239, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 327}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:42,969]\u001b[0m Trial 316 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8912101366663819, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 374}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:46,633]\u001b[0m Trial 317 finished with value: 2.9546555851939256 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8902019520030774, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 321}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:52,584]\u001b[0m Trial 318 finished with value: 2.935685083844366 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8932692847010322, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 351}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:56,100]\u001b[0m Trial 319 finished with value: 2.9119719571574163 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8883466582051388, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 424}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:07:59,113]\u001b[0m Trial 320 finished with value: 2.9404277091817557 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.8954141247215001, 'learning_rate': 0.05, 'leaf_estimation_iterations': 3, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 342}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n",
      "\u001b[32m[I 2023-05-11 13:08:02,083]\u001b[0m Trial 321 finished with value: 2.883516205133077 and parameters: {'bootstrap_type': 'Bernoulli', 'od_wait': 8, 'random_strength': 5, 'max_bin': 8, 'reg_lambda': 4, 'subsample': 0.9440651417276077, 'learning_rate': 0.05, 'leaf_estimation_iterations': 6, 'depth': 4, 'random_state': 2023, 'min_data_in_leaf': 328}. Best is trial 62 with value: 2.973626086543485.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/fd/5j4f_x491qxgc08q7_49187m0000gn/T/ipykernel_20316/2666787144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Number of finished trials:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best trial:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/fd/5j4f_x491qxgc08q7_49187m0000gn/T/ipykernel_20316/1665063106.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial, train, valid, oot, sel_cols, target)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     cat_model.fit(train[sel_cols], train[target], eval_set=[(train[sel_cols], train[target]), (oot_sample1[sel_cols], oot_sample1[target])],\n\u001b[0;32m---> 22\u001b[0;31m              early_stopping_rounds=20, verbose=False)   \n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proba'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moot_sample1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msel_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   4921\u001b[0m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[1;32m   4922\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4923\u001b[0;31m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0m\u001b[1;32m   4924\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2195\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2196\u001b[0m                 \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2197\u001b[0;31m                 \u001b[0mtrain_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"init_model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2198\u001b[0m             )\n\u001b[1;32m   2199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/young_envs/lib/python3.7/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1619\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_clear_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_object\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_model\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_trained_model_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=500)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "young_envs",
   "language": "python",
   "name": "young_envs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
